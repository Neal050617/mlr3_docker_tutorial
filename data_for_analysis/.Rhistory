tsk_right = task$clone()
tsk_right$select(select_name[1:biomaker_num])
set.seed(123, kind = "Mersenne-Twister")
## 指定算法与优化超参数
learner_rf = mlr3::lrn("classif.ranger",
predict_type = "prob",
importance = 'impurity',
predict_sets = c("train", "test"))
tune_ps_rf = ps(
num.trees = p_int(lower = 500, upper = 1000),
max.depth =  p_int(lower = 3, upper = 5),
min.node.size = p_int(lower = 3, upper =  10),
mtry = p_int(lower = ceiling(sqrt(biomaker_num)), upper = min(biomaker_num,ceiling(sqrt(biomaker_num))+2) )
)
learner_rf = auto_tuner(
tuner = tnr("random_search"),
learner = learner_rf,
resampling = rsmp("cv", folds = folds),
measure = msr("classif.auc"),
search_space = tune_ps_rf ,
term_evals =  term_evals,
)
plan("multisession",workers=workers)
nbrOfWorkers()
start<-Sys.time()
print(start)
train = learner_rf$train(tsk_right, row_ids = split_gp$train)
end<-Sys.time()
print(end)
runningtime<-end-start
print(runningtime)
plan(sequential)
prediction_test = learner_rf$predict(tsk_right, row_ids = split_gp$test)
# 是否修改阈值
# prediction_test$set_threshold(0.6666667) 提高了 先放这，有人是提出了不同的方法
# prediction_test$score(msr("classif.acc"))  0.8285714 原来 0.7几
# prediction_test$score(msr("classif.auc"))
measures = msrs(c("classif.auc","classif.acc", "classif.tpr",'classif.fpr'))
test_measures = prediction_test$score(measures) %>% t()%>%
as.data.frame(.,row.names="test_measures")%>%
mutate(bio_num = biomaker_num)%>%
rownames_to_column()%>%
select(rowname,bio_num,everything())
roc_plot <- list()
# 是否要训练集的结果
if (train_re == T){
prediction_train = learner_rf$predict(tsk_right, row_ids = split_gp$train)
train_measures = prediction_train$score(measures) %>% t()%>%
as.data.frame(.,row.names="train_measures")%>%
mutate(bio_num = biomaker_num)%>%
rownames_to_column()%>%
select(rowname,bio_num,everything())
pod_train = prediction_train$print() %>% as.data.frame() #pod_test = prediction_test$print() %>% as.data.frame()
write.xlsx(pod_train,'./训练集概率表.xlsx')
roc_plot[["train"]] <- roc_pict(pod = pod_train,title="train")
test_measures = rbind(train_measures, test_measures)
}
# https://ayueme.github.io/R_clinical_model/roc-bootstrap.html
# autoplot(prediction_test, type = "roc")
# POD值
pod_test = prediction_test$print() %>% as.data.frame()
write.xlsx(pod_test,'./测试集预测概率表.xlsx')
roc_plot[["test"]] <- roc_pict(pod = pod_test,title="test")
# 如果有外部验证
if(ex_valid == T){
external_valid = learner_rf$predict_newdata(external_data)
measures = msrs(c("classif.auc","classif.acc", "classif.tpr",'classif.fpr'))
external_measures = external_valid$score(measures) %>% t()%>%
as.data.frame(.,row.names="external_measures") %>%
mutate(bio_num = biomaker_num) %>%
rownames_to_column() %>%
select(rowname,bio_num,everything())
test_measures = rbind(test_measures,external_measures)
pod_external = external_valid$print() %>% as.data.frame()
write.xlsx(pod_external,'./外部测试集预测概率表.xlsx')
roc_plot[["external"]] <- roc_pict(pod =  pod_external,title="external")
}
ComBn_plot(roc_plot)
# 特征重要性
learner_rf$importance()
# 最优超参数
learner_rf$tuning_result$learner_param_vals[[1]]
### 特征重要性数据 改成原来的名字
data_var_imp = enframe(
learner_rf$importance(),
name = "variable",
value = "importance"
)
data_var_imp$old_colnames <- map_chr(data_var_imp$variable, function(x) {
feature_row <- names_values[names_values$new_colnames == x, ]
feature_row$old_colnames
})
data_var_imp$old_colnames <-  factor(data_var_imp$old_colnames,levels = rev(data_var_imp$old_colnames))
data_var_imp$old_colnames_n <- Add_breaks(data_var_imp$old_colnames)
data_var_imp$old_colnames_n <- factor(data_var_imp$old_colnames_n,levels = rev(data_var_imp$old_colnames_n))
### 特征重要性图 可以美化哈
w <- plot_p_feat(data_var_imp)
ComBn_plot(roc_plot,w)
setwd(old.wd)
return(list(test_measures,learner_rf$importance(),learner_rf$tuning_result$learner_param_vals[[1]]))
}
ComBn_plot <- function(P,w){#nc=2,
# P <- roc_plot
if (length(P) == 3){
layout <- "
AABBGGGGG
CCDDGGGGG
EEFFHHHHH"
}else if (length(P) == 3){
layout <- "
AABBGGGGGHH
CCDDGGGGGHH"
}else if (length(P) == 3){
layout <- "AABBGGGGGHH"
}
Q <- P[[1]][[1]] + P[[1]][[2]]
if (length(P) > 1){ for (i in 2:length(P)){ Q <- Q + P[[i]][[1]] + P[[i]][[2]]} }
Q <- Q + w + plot_layout(design = layout,guides = 'collect') +
plot_annotation(tag_levels = c('A', '1')) + # ncol = 2, byrow = TRUE
gridExtra::tableGrob(t(as.data.frame(learner_rf$tuning_result$learner_param_vals[[1]])))
ggsave(paste0("roc.pdf"),Q,dpi = 300,device = cairo_pdf,
width = 18,
height = 4*length(P))
}
# 曲线找拐点
knee_point <- function(y){
kk <- boxplot.stats(y)$conf[[2]]
return(kk)
}
# 太长的话加换行符
Add_breaks <- function(x){# x <- data_var_imp$old_colnames_n
xixi <- unique(as.character(x))
kk <- knee_point(nchar(xixi))
if (max(nchar(xixi))-kk < 5){
hehe <- xixi
}else{
haha <- floor(kk)
hehe <- map_chr(xixi,function(x) {# x <- xixi[9]
xx <- strsplit(x,'')[[1]]
ifelse(length(xx) > haha,str_c(str_c(xx[1:haha],collapse = ''),"\n",
str_c(xx[(haha+1):length(xx)],collapse = '')),x)
})
}
return(hehe)
}
plot_p_feat <- function(data_var_imp){
p_feat <- ggplot(data_var_imp, aes( x = old_colnames_n, y = importance, fill = importance)) +
geom_bar(stat = "identity", position = "dodge") +
coord_flip() +
ylab("Variable Importance") + xlab("") + #ggtitle("Information Value Summary") +
guides(fill = "none") +
scale_fill_gradient(low = "#327eba", high = "#e06663")+
theme_bw()+
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
ggsave('01.MeanDecreaseAccuracy.pdf',p_feat,width = 10,height = 6)
return(p_feat)
}
# 02.Read_in --------------------------------------------------------------
mapcol <- c("#61d04f","#df536b","#377EB8","#984EA3","#FF7F00","#FFFF33","#A65628","#F781BF") # ,"#4DAF4A","#E41A1C" RColorBrewer::brewer.pal(n = 8,name = "Set1")
Gp <- read_tsv(opts$map) %>% rename_all(~c("SampleID","group")) %>% mutate(group = fct_inorder(group))
# 指定分组顺序，要求对照组在前，实验组在后，重要
if (opts$gp != "none"){
gp <- strsplit(opts$gp,split = "-")[[1]]
if (length(gp) == 1) stop("Length of variable gp is equal to 1. Program terminated.")
Gp <- Gp %>% filter(group %in% gp) %>% mutate(group = factor(group,levels=gp))
if (length(unique(Gp$group)) == 1)  stop("Length of variable Gp  is equal to 1. Program terminated.")
}else{
gp <- levels(Gp$group)
}
# 指定分组颜色，对照组为绿色，实验组为红色
if (opts$color != "none"){# opts$color = c("color.txt")
sc <- read.table(opts$color,sep="\t",comment.char = "",check.names = FALSE)
sc <- sc[which(as.vector(sc[,1]) %in% unique(unlist(Gp$group))),]
Gp$group <- factor(Gp$group,levels = as.vector(sc[,1]))
Gp <- Gp %>% arrange(group)
} else{
sc <- cbind(levels(Gp$group),mapcol[1:nlevels(Gp$group)]) %>%
as.data.frame(stringsAsFactors = FALSE)
}
# 列是物质名 行是样本名，最后一列是group分组，其他都可以自行选择喜欢的
Data <- read_tsv(opts$input) %>% rename_at(1,~"Features")
if (isTRUE(opts$unif)){ Data <- Data %>% mutate(across(where(is.numeric), ~ . / sum(.))) }
Data <- Data %>%
pivot_longer(!Features) %>% pivot_wider(names_from = "Features",values_from = "value") %>% rename_at(1,~"SampleID") %>%
inner_join(Gp)
## 注意！！！ 因为列名即物质名 大多都比较奇怪，现在的算法不支持这种奇怪的名字
## data external_data 都需要处理，此外data external_data的物质名顺序需一致
## 此外在特征重要性中需要物质名，所以下面是处理方式
names_values <- tibble(
old_colnames = colnames(Data),
new_colnames = c("SampleID",paste0("feature_", seq(1, length(old_colnames)-2)),'group')
)
colnames(Data) <-  names_values$new_colnames
## 最初的随机森林代码，拿到特征重要性，排序，然后循环
rf_vari_imp = ranger(formula = group~., # group
data = Data[,-1], # data
num.trees = 1000,
importance = "permutation",seed = 42) #permutation
sort_var_imp = sort(rf_vari_imp[["variable.importance"]],decreasing = T)
select_name = names(sort(rf_vari_imp[["variable.importance"]],decreasing = T)[1:20])
### 特征重要性数据 改成原来的名字
data_var_imp = enframe(
rf_vari_imp[["variable.importance"]][select_name],
name = "variable",
value = "importance"
)
data_var_imp$old_colnames <- map_chr(data_var_imp$variable, function(x) {
feature_row <- names_values[names_values$new_colnames == x, ]
feature_row$old_colnames
})
data_var_imp$old_colnames <-  factor(data_var_imp$old_colnames,levels = rev(data_var_imp$old_colnames))
data_var_imp$old_colnames_n <- Add_breaks(data_var_imp$old_colnames)
data_var_imp$old_colnames_n <- factor(data_var_imp$old_colnames_n,levels = rev(data_var_imp$old_colnames_n))
### 特征重要性图 可以美化哈
plot_p_feat(data_var_imp)
# 03.建模准备 ------------------------------------------------------------------
# 参数
# biomaker_num 就是i
# positive 二分类需要,此外，如果因子化的字符串变量，直接输入字符串即可
# 比如 positive = 'OR'
# term_evals
# return tab2
task <- as_task_classif(Data,target = 'group',positive = gp[1])
if(grepl("/",opts$part)){
aa <- strsplit(opts$part,'/')[[1]][1] %>% as.numeric ; bb <- strsplit(opts$part,'/')[[1]][2] %>% as.numeric
}else{
aa <- strsplit(MASS::fractions(opts$part %>% as.numeric) %>% as.character,'/')[[1]][1] %>% as.numeric
bb <- strsplit(MASS::fractions(opts$part %>% as.numeric) %>% as.character,'/')[[1]][2] %>% as.numeric
}
zz <- aa/bb
if (opts$split == "none"){
split_gp <- partition(task = task,ratio = zz,stratify = T)
bind_rows(map(split_gp,as_tibble), .id = "Split") %>% mutate(value = Data$SampleID[value]) %>%
rename_at(2,~"SampleID") %>%
left_join(Data[,c("SampleID","group")] %>% mutate(group = as.character(group)),.) %>%
write_tsv("split.map-group.txt")
}else{
#split_gp_pre <- Data %>% dplyr::select(SampleID, group) %>% group_by(group) %>% nest() %>%
#  mutate(
#    num = map_dbl(data, ~nrow(.x)), num2 = map_dbl(num, ~floor(.x * zz)),
#    data2 = map2(data, num2, ~dplyr::slice_sample(.x, n = .y, replace = FALSE)),
#    data3 = map2(data,data2,~setdiff(pull(.x,SampleID), pull(.y,SampleID))),
#    data = map(data, ~factor(pull(.x, SampleID), levels = pull(.x, SampleID)))
#  ) %>% mutate(train = map(data2, ~factor(pull(.x, SampleID), levels = Data$SampleID) %>% as.numeric()),
#         test = map(data3, ~factor(.x, levels = Data$SampleID) %>% as.numeric()))
#split_gp <- list(train=unlist(split_gp_pre$train),test=unlist(split_gp_pre$test))
split_gp_pre <- Data[,c("SampleID","group")] %>%
left_join(read_tsv(opts$split) %>% rename_all(~c("SampleID","group","Split"))) %>%
mutate(Split = factor(Split,levels=c("train","test"))) %>%
group_by(group) %>% nest() %>%
mutate(data2 = map(data,~dplyr::filter(.x,Split == "train") %>% dplyr::select(SampleID)),
data3 = map(data,~dplyr::filter(.x,Split == "test") %>% dplyr::select(SampleID))
) %>%
mutate(train = map(data2, ~factor(pull(.x, SampleID), levels = Data$SampleID) %>% as.numeric()),
test =  map(data3, ~factor(pull(.x, SampleID), levels = Data$SampleID) %>% as.numeric()))
split_gp <- list(train=unlist(split_gp_pre$train),test=unlist(split_gp_pre$test))
}
# 04.建模 -------------------------------------------------------------------
# 外部验证最后再说
if (opts$valid != "none" & opts$map2 != "none"){
Gp2 <- read_tsv(opts$map2) %>% rename_all(~c("SampleID","group")) %>% filter(group %in% gp) %>% mutate(group = factor(group,levels=gp))
if (length(unique(Gp2$group)) == 1)  stop("Length of variable Gp2  is equal to 1. Program terminated.")
external_data <- read_tsv(opts$valid) %>% rename_at(1,~"Features")
if (isTRUE(opts$unif)){ external_data <- external_data %>% mutate(across(where(is.numeric), ~ . / sum(.))) }
external_data <- left_join(names_values,external_data,by=c("old_colnames"="Features")) %>%
dplyr::select(-old_colnames) %>% slice(-1,-n()) %>%
pivot_longer(!new_colnames) %>% pivot_wider(names_from = "new_colnames",values_from = "value") %>%
mutate_if(is.numeric, ~ replace(., is.na(.), 0)) %>%
rename_at(1,~"SampleID") %>% inner_join(Gp2)
}
d1 <- map_dfr(3:5,biomaker_select,task = task,ex_valid = (opts$valid!="none") )
w <- plot_p_feat(data_var_imp)
w
ComBn_plot
biomaker_select <- function(
biomaker_num ,
task = task,
ex_valid = T, # 是否有外部验证
train_re = T, # 是否要训练集结果
workers= 8, # 开始并行
folds = 5L, # 几折
term_evals = 100, # 超参数训练多少次
names_values=names_values) # featrue重命名
{
dir <- paste0('./',biomaker_num,'个代谢物建模')
print(dir)
if(!dir.exists(dir)) dir.create(dir)
old.wd <- getwd()
setwd(dir)
# biomaker_num  = 10
tsk_right = task$clone()
tsk_right$select(select_name[1:biomaker_num])
set.seed(123, kind = "Mersenne-Twister")
## 指定算法与优化超参数
learner_rf = mlr3::lrn("classif.ranger",
predict_type = "prob",
importance = 'impurity',
predict_sets = c("train", "test"))
tune_ps_rf = ps(
num.trees = p_int(lower = 500, upper = 1000),
max.depth =  p_int(lower = 3, upper = 5),
min.node.size = p_int(lower = 3, upper =  10),
mtry = p_int(lower = ceiling(sqrt(biomaker_num)), upper = min(biomaker_num,ceiling(sqrt(biomaker_num))+2) )
)
learner_rf = auto_tuner(
tuner = tnr("random_search"),
learner = learner_rf,
resampling = rsmp("cv", folds = folds),
measure = msr("classif.auc"),
search_space = tune_ps_rf ,
term_evals =  term_evals,
)
plan("multisession",workers=workers)
nbrOfWorkers()
start<-Sys.time()
print(start)
train = learner_rf$train(tsk_right, row_ids = split_gp$train)
end<-Sys.time()
print(end)
runningtime<-end-start
print(runningtime)
plan(sequential)
prediction_test = learner_rf$predict(tsk_right, row_ids = split_gp$test)
# 是否修改阈值
# prediction_test$set_threshold(0.6666667) 提高了 先放这，有人是提出了不同的方法
# prediction_test$score(msr("classif.acc"))  0.8285714 原来 0.7几
# prediction_test$score(msr("classif.auc"))
measures = msrs(c("classif.auc","classif.acc", "classif.tpr",'classif.fpr'))
test_measures = prediction_test$score(measures) %>% t()%>%
as.data.frame(.,row.names="test_measures")%>%
mutate(bio_num = biomaker_num)%>%
rownames_to_column()%>%
select(rowname,bio_num,everything())
roc_plot <- list()
# 是否要训练集的结果
if (train_re == T){
prediction_train = learner_rf$predict(tsk_right, row_ids = split_gp$train)
train_measures = prediction_train$score(measures) %>% t()%>%
as.data.frame(.,row.names="train_measures")%>%
mutate(bio_num = biomaker_num)%>%
rownames_to_column()%>%
select(rowname,bio_num,everything())
pod_train = prediction_train$print() %>% as.data.frame() #pod_test = prediction_test$print() %>% as.data.frame()
write.xlsx(pod_train,'./训练集概率表.xlsx')
roc_plot[["train"]] <- roc_pict(pod = pod_train,title="train")
test_measures = rbind(train_measures, test_measures)
}
# https://ayueme.github.io/R_clinical_model/roc-bootstrap.html
# autoplot(prediction_test, type = "roc")
# POD值
pod_test = prediction_test$print() %>% as.data.frame()
write.xlsx(pod_test,'./测试集预测概率表.xlsx')
roc_plot[["test"]] <- roc_pict(pod = pod_test,title="test")
# 如果有外部验证
if(ex_valid == T){
external_valid = learner_rf$predict_newdata(external_data)
measures = msrs(c("classif.auc","classif.acc", "classif.tpr",'classif.fpr'))
external_measures = external_valid$score(measures) %>% t()%>%
as.data.frame(.,row.names="external_measures") %>%
mutate(bio_num = biomaker_num) %>%
rownames_to_column() %>%
select(rowname,bio_num,everything())
test_measures = rbind(test_measures,external_measures)
pod_external = external_valid$print() %>% as.data.frame()
write.xlsx(pod_external,'./外部测试集预测概率表.xlsx')
roc_plot[["external"]] <- roc_pict(pod =  pod_external,title="external")
}
ComBn_plot(roc_plot)
# 特征重要性
learner_rf$importance()
# 最优超参数
learner_rf$tuning_result$learner_param_vals[[1]]
### 特征重要性数据 改成原来的名字
data_var_imp = enframe(
learner_rf$importance(),
name = "variable",
value = "importance"
)
data_var_imp$old_colnames <- map_chr(data_var_imp$variable, function(x) {
feature_row <- names_values[names_values$new_colnames == x, ]
feature_row$old_colnames
})
data_var_imp$old_colnames <-  factor(data_var_imp$old_colnames,levels = rev(data_var_imp$old_colnames))
data_var_imp$old_colnames_n <- Add_breaks(data_var_imp$old_colnames)
data_var_imp$old_colnames_n <- factor(data_var_imp$old_colnames_n,levels = rev(data_var_imp$old_colnames_n))
### 特征重要性图 可以美化哈
w <- plot_p_feat(data_var_imp)
ComBn_plot(roc_plot,w=w)
setwd(old.wd)
return(list(test_measures,learner_rf$importance(),learner_rf$tuning_result$learner_param_vals[[1]]))
}
d1 <- map_dfr(3:5,biomaker_select,task = task,ex_valid = (opts$valid!="none") )
biomaker_num <- 3
biomaker_select <- function(
biomaker_num ,
task = task,
ex_valid = T, # 是否有外部验证
train_re = T, # 是否要训练集结果
workers= 8, # 开始并行
folds = 5L, # 几折
term_evals = 100, # 超参数训练多少次
names_values=names_values) # featrue重命名
{
dir <- paste0('./',biomaker_num,'个代谢物建模')
print(dir)
if(!dir.exists(dir)) dir.create(dir)
old.wd <- getwd()
setwd(dir)
# biomaker_num  = 10
tsk_right = task$clone()
tsk_right$select(select_name[1:biomaker_num])
set.seed(123, kind = "Mersenne-Twister")
## 指定算法与优化超参数
learner_rf = mlr3::lrn("classif.ranger",
predict_type = "prob",
importance = 'impurity',
predict_sets = c("train", "test"))
tune_ps_rf = ps(
num.trees = p_int(lower = 500, upper = 1000),
max.depth =  p_int(lower = 3, upper = 5),
min.node.size = p_int(lower = 3, upper =  10),
mtry = p_int(lower = ceiling(sqrt(biomaker_num)), upper = min(biomaker_num,ceiling(sqrt(biomaker_num))+2) )
)
learner_rf = auto_tuner(
tuner = tnr("random_search"),
learner = learner_rf,
resampling = rsmp("cv", folds = folds),
measure = msr("classif.auc"),
search_space = tune_ps_rf ,
term_evals =  term_evals,
)
plan("multisession",workers=workers)
nbrOfWorkers()
start<-Sys.time()
print(start)
train = learner_rf$train(tsk_right, row_ids = split_gp$train)
end<-Sys.time()
print(end)
runningtime<-end-start
print(runningtime)
plan(sequential)
prediction_test = learner_rf$predict(tsk_right, row_ids = split_gp$test)
# 是否修改阈值
# prediction_test$set_threshold(0.6666667) 提高了 先放这，有人是提出了不同的方法
# prediction_test$score(msr("classif.acc"))  0.8285714 原来 0.7几
# prediction_test$score(msr("classif.auc"))
measures = msrs(c("classif.auc","classif.acc", "classif.tpr",'classif.fpr'))
test_measures = prediction_test$score(measures) %>% t()%>%
as.data.frame(.,row.names="test_measures")%>%
mutate(bio_num = biomaker_num)%>%
rownames_to_column()%>%
select(rowname,bio_num,everything())
roc_plot <- list()
# 是否要训练集的结果
if (train_re == T){
prediction_train = learner_rf$predict(tsk_right, row_ids = split_gp$train)
train_measures = prediction_train$score(measures) %>% t()%>%
as.data.frame(.,row.names="train_measures")%>%
mutate(bio_num = biomaker_num)%>%
rownames_to_column()%>%
select(rowname,bio_num,everything())
pod_train = prediction_train$print() %>% as.data.frame() #pod_test = prediction_test$print() %>% as.data.frame()
write.xlsx(pod_train,'./训练集概率表.xlsx')
roc_plot[["train"]] <- roc_pict(pod = pod_train,title="train")
test_measures = rbind(train_measures, test_measures)
}
# https://ayueme.github.io/R_clinical_model/roc-bootstrap.html
# autoplot(prediction_test, type = "roc")
# POD值
pod_test = prediction_test$print() %>% as.data.frame()
write.xlsx(pod_test,'./测试集预测概率表.xlsx')
roc_plot[["test"]] <- roc_pict(pod = pod_test,title="test")
# 如果有外部验证
if(ex_valid == T){
external_valid = learner_rf$predict_newdata(external_data)
measures = msrs(c("classif.auc","classif.acc", "classif.tpr",'classif.fpr'))
external_measures = external_valid$score(measures) %>% t()%>%
as.data.frame(.,row.names="external_measures") %>%
mutate(bio_num = biomaker_num) %>%
rownames_to_column() %>%
select(rowname,bio_num,everything())
test_measures = rbind(test_measures,external_measures)
pod_external = external_valid$print() %>% as.data.frame()
write.xlsx(pod_external,'./外部测试集预测概率表.xlsx')
roc_plot[["external"]] <- roc_pict(pod =  pod_external,title="external")
}
# 特征重要性
learner_rf$importance()
# 最优超参数
learner_rf$tuning_result$learner_param_vals[[1]]
### 特征重要性数据 改成原来的名字
data_var_imp = enframe(
learner_rf$importance(),
name = "variable",
value = "importance"
)
data_var_imp$old_colnames <- map_chr(data_var_imp$variable, function(x) {
feature_row <- names_values[names_values$new_colnames == x, ]
feature_row$old_colnames
})
data_var_imp$old_colnames <-  factor(data_var_imp$old_colnames,levels = rev(data_var_imp$old_colnames))
data_var_imp$old_colnames_n <- Add_breaks(data_var_imp$old_colnames)
data_var_imp$old_colnames_n <- factor(data_var_imp$old_colnames_n,levels = rev(data_var_imp$old_colnames_n))
### 特征重要性图 可以美化哈
w <- plot_p_feat(data_var_imp)
ComBn_plot(roc_plot,w=w)
setwd(old.wd)
return(list(test_measures,learner_rf$importance(),learner_rf$tuning_result$learner_param_vals[[1]]))
}
d1 <- map_dfr(3:5,biomaker_select,task = task,ex_valid = (opts$valid!="none") )
setwd("D:/坚果云/我的坚果云/R/20240418_mlr3_randomforest")
